[00:00:00.779 --> 00:00:02.639]  Would you be okay with robot cops?
[00:00:04.460 --> 00:00:04.760]  Yes.
[00:00:05.840 --> 00:00:06.220]  No.
[00:00:07.000 --> 00:00:12.021]  I like having someone actually there in person and that I can relate to and just interact with.
[00:00:12.301 --> 00:00:17.342]  I think it's kind of frightening and I think a lot of times human judgment saves lives and is like really important.
[00:00:17.923 --> 00:00:21.743]  I assume it can be good that you will treat everybody more equal.
[00:00:22.003 --> 00:00:22.644]  Robocops?
[00:00:23.164 --> 00:00:24.364]  The real ones or the fake ones?
[00:00:24.804 --> 00:00:25.324]  Real ones.
[00:00:26.004 --> 00:00:27.084]  Uh, not too sure about that.
[00:00:27.165 --> 00:00:28.405]  I'm gonna be scared for my life.
[00:00:28.445 --> 00:00:29.125]  What you mean?
[00:00:30.145 --> 00:00:35.250]  Until they make machines that can think better than human beings, and even human beings make errors all the time.
[00:00:35.270 --> 00:00:38.453]  I mean, look at all the lawsuits for, you know, wrongful deaths.
[00:00:38.793 --> 00:00:43.057]  You lose, I guess, that sensitivity that your average person might have.
[00:00:43.077 --> 00:00:49.342]  A lot of things are black and white, and sometimes, you know, there's circumstances which I think there should be a little more slack with.
[00:00:49.382 --> 00:00:51.944]  Would you be like, oh, there's that robot, I hope he doesn't shoot me.
[00:00:52.805 --> 00:00:54.587]  I wouldn't give him a reason to shoot me, so.
[00:00:54.967 --> 00:00:56.008]  I wouldn't be scared, per se.
[00:00:56.786 --> 00:01:00.067]  Did you know that in some places it's against the law to grow a garden?
[00:01:00.087 --> 00:01:01.207]  Is it really?
[00:01:01.227 --> 00:01:02.367]  No, I didn't know that.
[00:01:02.927 --> 00:01:05.528]  Or they can ticket you for washing your car in your driveway.
[00:01:05.548 --> 00:01:08.008]  I did not know that.
[00:01:08.228 --> 00:01:09.269]  You're breaking the law.
[00:01:09.749 --> 00:01:11.489]  I mean... You have 30 seconds to comply.
[00:01:12.349 --> 00:01:17.090]  And then they put their twin rotary machine guns on you.
[00:01:18.291 --> 00:01:21.331]  This is a DARPA robot pet man.
[00:01:21.391 --> 00:01:22.412]  This is what they're working on.
[00:01:22.932 --> 00:01:23.552]  Look at that guy.
[00:01:23.852 --> 00:01:24.072]  Yeah.
[00:01:25.120 --> 00:01:26.081]  Isn't that scary?
[00:01:26.201 --> 00:01:27.643]  They're turning these into soldiers.
[00:01:28.804 --> 00:01:32.547]  Why do they need unmanned drones that can run at things?
[00:01:32.968 --> 00:01:34.269]  I don't understand the need for it.
[00:01:34.629 --> 00:01:42.377]  For someone to have that much power, you kind of need someone to be a... have more intelligence than some robot.
[00:01:42.417 --> 00:01:43.638]  Would you ever date a robot?
[00:01:44.179 --> 00:01:45.940]  No.
[00:01:46.160 --> 00:01:49.484]  I don't think you can replace the human heart, the human emotions.
[00:01:50.401 --> 00:01:52.742]  They're all just super computers anyway.
[00:01:52.762 --> 00:01:53.923]  I guess, in a way.
[00:01:53.943 --> 00:02:01.307]  I mean, it seems like it's a pretty easy way to just sort of say, this is exactly what I like, don't like, and what I want, and they could just ship it right to your door.
[00:02:01.787 --> 00:02:03.708]  Amazon could deliver it with a drone.
[00:02:03.728 --> 00:02:04.589]  I don't know.
[00:02:04.609 --> 00:02:09.952]  I guess they're old-fashioned, but people should, you know, get a life, not really date robots.
[00:02:10.052 --> 00:02:13.353]  All of a sudden, the computer goes down, and he's got to go to the hospital.
[00:02:14.494 --> 00:02:19.857]  He ends up being embarrassed and showing up at the emergency room with a robot attached to him.
[00:02:21.236 --> 00:02:25.298]  Upload your brain to some sort of an artificial reality and live forever?
[00:02:25.738 --> 00:02:27.479]  Doesn't that sound trendy?
[00:02:27.499 --> 00:02:30.360]  That's a cool idea.
[00:02:30.560 --> 00:02:31.460]  Lifespan extension.
[00:02:32.261 --> 00:02:37.623]  So you would be into uploading your brain to artificial reality?
[00:02:38.843 --> 00:02:40.904]  Not per se, but an artificial body maybe.
[00:02:41.144 --> 00:02:49.067]  What would you do with your students if they were basically able to upload all of their test information to their computer chips, basically like Google in their brain?
[00:02:49.708 --> 00:02:50.348]  I'd be scared.
[00:02:51.834 --> 00:02:53.096]  Because who knows what else is in there?
[00:02:53.136 --> 00:02:55.719]  No, I am not into any sort of virtual reality world.
[00:02:55.739 --> 00:02:58.904]  I would never want my brain uplinked into anything permanently.
[00:02:58.964 --> 00:03:03.130]  I don't want anybody to have any sort of manipulative control.
