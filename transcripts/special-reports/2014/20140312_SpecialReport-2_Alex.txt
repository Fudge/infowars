[00:00:06.135 --> 00:00:08.958]  I'm here at the Austin Convention Center during South by Southwest.
[00:00:09.078 --> 00:00:11.340]  Edward Snowden is the keynote speaker now.
[00:00:11.360 --> 00:00:15.924]  We're going to go around and find out what people think the impact surveillance has had on the tech industry.
[00:00:16.244 --> 00:00:16.824]  How are you doing?
[00:00:16.844 --> 00:00:17.465]  Good, how are you?
[00:00:17.725 --> 00:00:18.285]  Very well.
[00:00:18.305 --> 00:00:19.066]  Where are you guys from?
[00:00:19.086 --> 00:00:19.907]  Chicago.
[00:00:21.328 --> 00:00:22.129]  Oh, Chicago.
[00:00:22.209 --> 00:00:23.250]  Glad to be here in Texas.
[00:00:23.290 --> 00:00:24.811]  Yeah, there's sun, so that's nice.
[00:00:25.051 --> 00:00:25.592]  Where are you from?
[00:00:26.252 --> 00:00:27.413]  I'm from Birmingham, Alabama.
[00:00:27.974 --> 00:00:28.594]  Well, welcome.
[00:00:28.614 --> 00:00:29.455]  Are you enjoying Austin?
[00:00:29.904 --> 00:00:30.184]  I am.
[00:00:30.585 --> 00:00:30.745]  I am.
[00:00:30.885 --> 00:00:31.365]  Lots of fun.
[00:00:31.605 --> 00:00:32.066]  Hey guys!
[00:00:32.526 --> 00:00:33.207]  How are y'all doing?
[00:00:33.827 --> 00:00:34.408]  Where are you from?
[00:00:34.428 --> 00:00:35.188]  Here.
[00:00:35.789 --> 00:00:36.529]  From Austin!
[00:00:37.030 --> 00:00:37.330]  Welcome!
[00:00:37.370 --> 00:00:40.232]  Are you excited about Edward Snowden being the keynote speaker today?
[00:00:40.252 --> 00:00:42.834]  I think it's pretty cool, yeah, but I don't really want to be on camera.
[00:00:44.556 --> 00:00:45.516]  You got glasses on!
[00:00:45.576 --> 00:00:46.677]  No one can see who you are!
[00:00:46.697 --> 00:00:48.919]  So are you all familiar with Edward Snowden?
[00:00:49.239 --> 00:00:49.459]  Yeah.
[00:00:51.041 --> 00:00:55.104]  How do you feel the information that he shared has affected the tech industry?
[00:00:57.995 --> 00:00:59.197]  Very good, very good question.
[00:00:59.237 --> 00:01:03.862]  I think it's made everybody more aware and more nervous about, you know, before we were kind of pushing everything out.
[00:01:04.262 --> 00:01:07.927]  We didn't really care about what it was and we would share what we're eating for breakfast.
[00:01:07.987 --> 00:01:13.293]  Now it's, I would say, more nervous and more cautious about what we're doing.
[00:01:13.743 --> 00:01:15.324]  It's really unpredictable right now.
[00:01:15.384 --> 00:01:28.473]  I think that's why it's so interesting, because there's so many different directions in which it can go, and we struggle with it on the government level, and we struggle with it on a marketer level, and we struggle with it on an everyday consumer level, with everyone putting their information out there through social media.
[00:01:28.653 --> 00:01:31.235]  Are you much more concerned and cautious now?
[00:01:31.355 --> 00:01:32.596]  I'm not really concerned.
[00:01:32.616 --> 00:01:35.678]  I don't do anything sketchy on the internet, so I'm not worried.
[00:01:36.358 --> 00:01:37.939]  I don't know.
[00:01:37.979 --> 00:01:39.380]  I'm not really a private person.
[00:01:39.400 --> 00:01:41.001]  It seems sort of like...
[00:01:42.062 --> 00:01:47.084]  It's kind of a wonderful thing to have access to someone who's divulging so much important information.
[00:01:47.244 --> 00:01:49.785]  I think you're crazy if you're not concerned about privacy online.
[00:01:50.406 --> 00:01:52.727]  I'm going to interview my friend.
[00:01:52.747 --> 00:01:54.387]  That's super techy, right?
[00:01:54.527 --> 00:01:56.268]  Yeah, this is pretty intense right now.
[00:01:57.349 --> 00:02:00.290]  Are you guys going to the Edward Snowden talk right now?
[00:02:00.710 --> 00:02:02.491]  No, I'm not actually.
[00:02:02.531 --> 00:02:03.571]  I'm going to a film.
[00:02:04.051 --> 00:02:09.634]  Are you familiar with some of the things that are being leaked by Edward Snowden about how much it's affecting society?
[00:02:10.359 --> 00:02:10.839]  I'm not.
[00:02:11.300 --> 00:02:11.520]  What?
[00:02:11.680 --> 00:02:13.422]  I don't know what the Snowden leaks are.
[00:02:13.462 --> 00:02:15.403]  Is that something that came to the WikiLeaks?
[00:02:15.643 --> 00:02:18.165]  What am I supposed to say to that?
[00:02:18.185 --> 00:02:19.426]  Oh my goodness!
[00:02:19.747 --> 00:02:20.748]  You are not aware.
[00:02:21.108 --> 00:02:27.713]  You are building a mobile app and you do not know how this is going to... How are you going to protect your people that are going to download your app?
[00:02:27.933 --> 00:02:29.915]  Well, I just have to say thank you for keeping me informed.
[00:02:29.955 --> 00:02:31.977]  I'll probably have to do some more research and look into it.
[00:02:32.177 --> 00:02:32.417]  Yes.
[00:02:32.597 --> 00:02:38.062]  Do you think people should have a right to privacy on the internet or we should have internet rights?
[00:02:39.413 --> 00:02:41.915]  The internet is... you can live your life without it.
[00:02:42.275 --> 00:02:43.936]  So buyer beware, right?
[00:02:45.237 --> 00:02:49.099]  If you want to use that kind of technology, it comes with that kind of a catch.
[00:02:49.599 --> 00:02:51.100]  That's probably okay.
[00:02:51.670 --> 00:03:02.175]  So you don't mind that you're being watched like when you do yoga via the Xbox and stuff like that, or like your webcam photos are going to somebody at the NSA?
[00:03:02.416 --> 00:03:03.936]  Yeah, I guess that is kind of sketchy.
[00:03:04.337 --> 00:03:12.881]  I think it's really scary, and I think it's something that's really real that we kind of all need to think about in everyday lives, and we're so willing to offer up all the information.
[00:03:12.941 --> 00:03:20.745]  I actually am a marketer by trade, so I understand how much we rely on that sort of information, so I think it's a really delicate balance.
[00:03:21.045 --> 00:03:31.214]  The fact that the government is surveilling and that they are going to be monitoring electronic transmissions, I mean, you know, that's something that we should be aware of or we're naive.
[00:03:31.755 --> 00:03:33.216]  Do you guys catch Edward Snowden at all?
[00:03:34.978 --> 00:03:36.499]  Uh, yeah, but... I don't want to be on camera though.
[00:03:37.140 --> 00:03:37.660]  Alright.
[00:03:38.261 --> 00:03:46.128]  How do you feel about the way that WikiLeaks gets whistleblowers' information out there versus how Snowden's information is being given to the public?
[00:03:47.025 --> 00:03:51.169]  What is, how I feel about the difference between how Weaklink did and how he did?
[00:03:51.189 --> 00:03:54.473]  Yeah, all at once versus slow drips every couple of months.
[00:03:55.942 --> 00:04:00.286]  It seems a little more responsible to do it the way Snowden's doing it.
[00:04:00.606 --> 00:04:03.429]  I think if you're going to give it out, give it out.
[00:04:03.950 --> 00:04:07.213]  It's going to take, I mean look how long it took to go through the WikiLeaks, right?
[00:04:07.233 --> 00:04:09.315]  I think we're still going through the WikiLeaks stuff, right?
[00:04:10.155 --> 00:04:19.724]  So, someone who actually used to work for Homeland Security, I did a long time ago, information, if you just throw it out there, then let people decipher to
[00:04:20.714 --> 00:04:21.074]  I don't know.
[00:04:40.185 --> 00:04:47.610]  He worked on the legal team when the Enron affair was happening and really like things like that just disappear from the radar.
[00:04:47.650 --> 00:04:50.452]  People forget really sort of pivotal important things.
[00:04:50.952 --> 00:04:58.357]  So the more persistence and sort of incremental growth of information he can provide, the better I think.
[00:04:58.777 --> 00:04:59.718]  I think it's just the beginning.
[00:04:59.898 --> 00:05:04.641]  I think it was just the opening of things that are to come.
[00:05:04.921 --> 00:05:10.726]  As long as Americans continue to use tools that are developed by advertisers, then we can't expect to have privacy, right?
[00:05:10.746 --> 00:05:12.467]  So Google Chrome is the number one browser.
[00:05:12.487 --> 00:05:14.368]  Google's an advertising company.
[00:05:14.749 --> 00:05:19.012]  Do you think we're all just kind of being conditioned to just be okay with it and accept it?
[00:05:19.672 --> 00:05:20.453]  Uh, no.
[00:05:20.533 --> 00:05:24.176]  I mean, you have an option to either use it or not use it.
[00:05:24.196 --> 00:05:27.659]  And you use it, you're putting yourself up at risk.
[00:05:27.859 --> 00:05:30.841]  Well, what about all the people walking around with the Google glasses on?
[00:05:30.861 --> 00:05:31.822]  I think those are silly.
[00:05:33.987 --> 00:05:35.008]  Can't opt out of that.
[00:05:35.028 --> 00:05:35.888]  No, you can't.
[00:05:36.088 --> 00:05:37.369]  Or just run away, I guess.
[00:05:38.069 --> 00:05:40.470]  I feel like maybe people are a little bit desensitized now.
[00:05:40.870 --> 00:05:45.392]  It seems that people should be outraged, but they're kind of like, uh... Yeah, I agree.
[00:05:45.932 --> 00:05:49.754]  It's an unfortunate evolution of this technology that we don't have control.
[00:05:49.794 --> 00:05:51.235]  We did not know where it was going to go.
[00:05:51.555 --> 00:05:53.436]  Everyone's filming you everywhere!
[00:05:55.509 --> 00:05:57.089]  You can't opt out anymore?
[00:05:57.930 --> 00:06:01.191]  Well, it seems like this is just the beginning of what we've heard from Snowden.
[00:06:01.211 --> 00:06:04.232]  A lot of people agree with the way that it's being slowly leaked out.
[00:06:04.292 --> 00:06:09.953]  It keeps it in the news, but it's also a little bit more responsible in the name of national security, so people sort of understand that.
[00:06:10.394 --> 00:06:13.074]  But it also seems like a lot of people have really desensitized.
[00:06:13.334 --> 00:06:18.156]  Five years ago, if you told them that they were being spied on through their webcam or via their telephone,
[00:06:18.596 --> 00:06:25.541]  They would call you crazy conspiracy theorists, and now that it's out and it's a fact, people are just kind of desensitized to it.
[00:06:25.601 --> 00:06:34.987]  So it remains to be seen what else we're going to find out, but it also remains to be seen how we're going to be able to react to this advanced technology and just the pace of technology.
