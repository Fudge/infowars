[00:00:19.841 --> 00:00:22.043]  Welcome to the InfoWars Nightly News.
[00:00:22.103 --> 00:00:26.667]  It is Tuesday, January 27, 2015, and I'm Leigh Ann McAdoo.
[00:00:26.967 --> 00:00:28.348]  Here are tonight's top stories.
[00:00:30.930 --> 00:00:33.292]  Tonight, artificial intelligence.
[00:00:33.733 --> 00:00:35.294]  Friend or foe?
[00:00:35.854 --> 00:00:36.955]  Who will control it?
[00:00:37.456 --> 00:00:38.457]  Can it be controlled?
[00:00:39.137 --> 00:00:42.280]  And, epic snow fail in the Northeast.
[00:00:42.680 --> 00:00:46.964]  What does regional climate alarmism tell us about global climate alarmism?
[00:00:48.001 --> 00:00:50.802]  All that and more on tonight's InfoWars Nightly News.
[00:01:00.063 --> 00:01:02.884]  Well, this was breaking on InfoWars.com today.
[00:01:02.964 --> 00:01:08.085]  The UK government has announced plans to remotely control vehicles.
[00:01:08.625 --> 00:01:12.306]  The UK government's plan was released in a report.
[00:01:12.326 --> 00:01:21.109]  They're going to be using Wi-Fi technology on roads in order to reduce traffic and, of course, offset global warming.
[00:01:22.498 --> 00:01:24.598]  This report was released by Ofcom.
[00:01:25.118 --> 00:01:37.140]  It's a government-controlled body which regulates communications in the UK and its blueprint says it could be realized in about 10 years where cars would communicate with each other to reduce congestion.
[00:01:37.661 --> 00:01:51.443]  The proposals are being billed by some media outlets as a means of solving traffic jams and taking the stress out of finding a parking space while also serving to reduce greenhouse gases and offset global warming.
[00:01:51.963 --> 00:01:55.125]  However, buried deep in this report is this little detail.
[00:01:55.565 --> 00:02:06.931]  The state plans to achieve this new high-tech solution by fitting sensors in all cars that would wirelessly send information to a central traffic control system.
[00:02:07.411 --> 00:02:18.176]  And this control system would then react by imposing remote speed limits on each vehicle, having a shockwave effect which would cause each one to brake and accelerate in unison.
[00:02:18.557 --> 00:02:19.277]  So in other words,
[00:02:19.697 --> 00:02:28.045]  In the name of reducing traffic and of course helping the environment, the government can take control of your vehicle at any given moment.
[00:02:28.865 --> 00:02:35.812]  Of course, this is against your will and they'll be able to have a perfectly formed database of tracking all of your
[00:02:36.252 --> 00:02:39.433]  Your location and where you're headed every single day.
[00:02:39.493 --> 00:02:42.535]  So this is just going to, of course, be more data that they are collecting on us.
[00:02:42.955 --> 00:02:47.076]  But it's trendy and it's super cool to have smart cars and smart homes.
[00:02:47.496 --> 00:02:52.619]  And it's being billed as the Internet of Things, as this wonderful thing.
[00:02:53.319 --> 00:02:58.001]  There's actually an artificial intelligence conference going on in Austin, Texas, this week.
[00:02:58.181 --> 00:03:00.942]  People from all around the world are coming together to talk about
[00:03:01.582 --> 00:03:07.369]  What is the future of AI and what is humanity's place in that future?
[00:03:07.850 --> 00:03:16.159]  And what happens when the majority of jobs are being taken over by robots and humans are no longer needed for production?
[00:03:16.179 --> 00:03:21.285]  This was one of the big things that was happening there and I asked one of the attendees at the conference
[00:03:21.866 --> 00:03:26.490]  Just kind of saying, well, what are we supposed to do in 2045 when all of the jobs are taken over?
[00:03:26.530 --> 00:03:27.591]  What are humans supposed to do?
[00:03:27.651 --> 00:03:31.454]  And he just kind of scoffed at me and said, it's going to be a lot sooner than that.
[00:03:31.914 --> 00:03:34.996]  So that's just 20, 30 years away that we're talking.
[00:03:35.817 --> 00:03:38.379]  People are going to be in a jobs crisis.
[00:03:38.459 --> 00:03:39.820]  You think there's a crisis right now?
[00:03:40.241 --> 00:03:44.043]  Well, this is something that is really weighing heavy on the mind of economists there.
[00:03:44.764 --> 00:03:48.225]  They're all asking the AI community, what are we going to do?
[00:03:48.786 --> 00:03:51.767]  And the truth is, nobody has a clue.
[00:03:52.347 --> 00:03:55.668]  Now, we're already kind of seeing this beginning to happen.
[00:03:56.068 --> 00:03:58.009]  This is a report that came out today, exclusive.
[00:03:58.489 --> 00:04:04.411]  Apple supplier Foxconn to shrink the workforce as sales growth stalls.
[00:04:04.892 --> 00:04:11.134]  Now, this is Taiwan's Foxconn Technology Group, the world's largest contract electronics manufacturer.
[00:04:11.514 --> 00:04:13.595]  They say they're going to cut its massive workforce
[00:04:14.495 --> 00:04:17.216]  As the Apple ink supplier faces declining revenue.
[00:04:17.876 --> 00:04:20.917]  This is, of course, amid rising wages in China.
[00:04:21.397 --> 00:04:23.798]  So we're hearing that as well here in America as well.
[00:04:24.498 --> 00:04:42.804]  The special assistant to the chairman and group spokesman, Louis Wu, did not specify a time frame or target for this reduction, but he noted that labor costs had more than doubled since 2010, when the company faced intense media scrutiny following a spate of worker suicides.
[00:04:43.444 --> 00:04:50.410]  And I know we reported on that, that workers were actually plunging to their deaths, worker suicides, they were being overworked.
[00:04:50.810 --> 00:04:58.877]  So here now, these people dare ask for a pay raise, and so of course they're going to be replaced by robots who don't complain.
[00:04:59.957 --> 00:05:08.564]  Woo points out that as technology improves, the price of technology is going to come down and they're not going to pay higher wages.
[00:05:09.164 --> 00:05:21.954]  And he said automation will be key to keeping labor costs under control in the long term as the company pushes to have robotic arms complete the mundane tasks that are currently done by workers.
[00:05:22.454 --> 00:05:28.039]  But Woo noted that company chairman previously stated a goal of one million robots
[00:05:28.479 --> 00:05:31.700]  Was kind of a generic concept rather than a firm target.
[00:05:32.040 --> 00:05:37.382]  So here we have companies that are openly talking about replacing their workers with robots.
[00:05:37.542 --> 00:05:42.804]  Workers who they so clearly cared about because they were plunging to their deaths.
[00:05:43.971 --> 00:05:49.356]  But again, like I said at this Artificial Intelligence Conference, that's what all the discussions were about that day.
[00:05:49.376 --> 00:05:50.837]  That's what the panels were about.
[00:05:51.178 --> 00:05:54.281]  What is happening to human employment?
[00:05:54.421 --> 00:05:55.402]  What are we to do?
[00:05:55.802 --> 00:05:59.806]  The economists there, that's their number one burning question because they've looked at all the models.
[00:06:00.126 --> 00:06:05.471]  And it just doesn't work to have a lot of humans walking around with machines taking care of all the labor.
[00:06:05.811 --> 00:06:08.814]  That's, for whatever reason, that's not sustainable to them.
[00:06:09.234 --> 00:06:14.238]  You know, God forbid humans are allowed to just write poetry and have a day at the beach.
[00:06:14.679 --> 00:06:15.780]  So that does not work.
[00:06:16.080 --> 00:06:16.540]  Why not?
[00:06:16.780 --> 00:06:17.301]  I don't know.
[00:06:17.361 --> 00:06:21.064]  But that's the scary thing is that nobody knows what is going to happen in
[00:06:22.185 --> 00:06:30.310]  Anywhere to the next 30 years, probably much sooner than that, what's going to happen with all of these humans kind of wandering around in this transition period?
[00:06:30.670 --> 00:06:39.196]  And of course, robots are not going to have any problem replacing you or possibly annihilating you if that's what they're programmed to do.
[00:06:39.216 --> 00:06:42.037]  Now, a lot of the folks that I spoke with yesterday
[00:06:43.178 --> 00:06:51.703]  They were very concerned with this pending short-term crisis, but a lot less concerned with this spontaneous malevolence, the rise of the robots.
[00:06:52.864 --> 00:06:58.768]  Based on their technological know-how, they said they really don't think that's a likely scenario.
[00:06:59.148 --> 00:07:07.093]  But what frightens them are the evil humans that would be using this technology to do their evil bidding.
[00:07:07.433 --> 00:07:12.156]  And that was what this talk was really about, is raising the question of ethics.
[00:07:13.016 --> 00:07:17.781]  And I'm going to play a snippet of this interview coming up later with Dr. Stuart Russell.
[00:07:17.841 --> 00:07:30.273]  He is the author of Artificial Intelligence, but he's also a signer of an open letter that was signed by a lot of really important people in the AI community, a lot of people like Elon Musk.
[00:07:31.674 --> 00:07:33.336]  This is an open letter at futureoflife.org.
[00:07:35.758 --> 00:07:49.309]  And basically what they are suggesting is the focus, they're calling for the focus to not just be on making AI more capable, but on maximizing the societal benefit of AI.
[00:07:49.389 --> 00:07:53.933]  They say, let's not create things that are going to wipe out humanity, let's just be smart.
[00:07:54.313 --> 00:08:04.902]  And so basically they suggest research priorities to optimize AI's economic impact so that it avoids destroying jobs in a way that will increase income inequality.
[00:08:05.562 --> 00:08:11.907]  It wants to determine how AI should handle ethical questions like those surrounding autonomous vehicle collisions.
[00:08:11.967 --> 00:08:12.727]  What are the laws?
[00:08:12.767 --> 00:08:15.049]  What are the liabilities with autonomous vehicles?
[00:08:15.589 --> 00:08:27.918]  And then, of course, how they can ensure human control over something like an autonomous weapon system and all other sorts of issues that are going to rise, of course, out of this emerging field.
[00:08:28.638 --> 00:08:30.619]  And you can actually sign on to that letter as well.
[00:08:30.699 --> 00:08:33.040]  It is at futureoflife.org.
[00:08:33.420 --> 00:08:46.424]  Like I said, Elon Musk is one of the signers of that and he also donated about $10 million to research these ways to keep robots from murdering all of us.
[00:08:46.624 --> 00:08:52.787]  So here we have, you know, he's trying to build SpaceX and wants to get the internet in space and AI is coming.
[00:08:52.827 --> 00:08:53.587]  They are going to
[00:08:54.648 --> 00:09:06.578]  Yes, we do need to maybe just consider the possibility that robots could, you know, kill us all.
[00:09:06.999 --> 00:09:12.264]  They say it might seem impossible, but nothing is impossible, especially to scientists.
[00:09:12.284 --> 00:09:16.448]  But the good news is it doesn't exist yet.
[00:09:17.148 --> 00:09:18.229]  It's not Checkmate.
[00:09:19.210 --> 00:09:23.412]  We see all of these sci-fi movies and we think that it's over and there's nowhere to go.
[00:09:23.973 --> 00:09:25.074]  It's not invented yet.
[00:09:25.254 --> 00:09:38.363]  We actually have an opportunity to play a role in this and to let our voices be heard and to let the good people that are working very hard behind the scenes to bring this technology, make sure that they steer it in the right direction.
[00:09:41.414 --> 00:09:50.636]  I like to use the example of thinking about 100 years ago when all of our grandparents had the opportunity to say no to the IRS and the Federal Reserve.
[00:09:51.397 --> 00:09:52.317]  But they didn't.
[00:09:52.557 --> 00:09:55.778]  Maybe it's because they were just so beaten down and broke.
[00:09:56.438 --> 00:10:01.001]  With everything that was going on in the economy then, everyone was poor and of course that was by design.
[00:10:01.441 --> 00:10:13.508]  So they were sold this idea that the IRS and the Federal Reserve and you know taxes and everything was going to help them and save them and of course that altered the course of history and that's exactly where we are today.
[00:10:13.628 --> 00:10:18.911]  We are at the precipice of a decision that could completely alter the course of humanity.
[00:10:19.311 --> 00:10:24.434]  So we need to stay vigilant and we need to stay aware and awake and conscious of what is happening.
[00:10:25.234 --> 00:10:28.619]  Now it's not checkmate for the surveillance state either.
[00:10:28.639 --> 00:10:37.030]  The Electronic Frontier Foundation has released their master plan for helping to end global mass surveillance.
[00:10:37.410 --> 00:10:40.394]  They actually give you some solutions and
[00:10:41.115 --> 00:10:47.457]  Kind of a game plan on how to get a hold of those who do have a nefarious agenda with using the surveillance state.
[00:10:48.197 --> 00:10:54.158]  Some of the things they talk about are pressuring technology companies to harden their systems against NSA surveillance.
[00:10:54.699 --> 00:10:56.299]  We've seen the power in numbers.
[00:10:56.379 --> 00:11:03.741]  We've seen how public pressure has been able to force companies like Heineken to take the caramel coloring out of their beer
[00:11:04.561 --> 00:11:13.846]  Or big success again with the food babe, able to force Subway to take the yoga foam, yoga mat foam out of their bread.
[00:11:13.986 --> 00:11:16.848]  So there's huge power in numbers in public pressure.
[00:11:16.868 --> 00:11:18.729]  So that's one big thing that we need to do.
[00:11:18.769 --> 00:11:24.172]  There's a ton of companies that would be really upset if they lost billions of customers.
[00:11:24.492 --> 00:11:28.815]  But of course they talk about creating a global movement that encourages user side encryption,
[00:11:29.395 --> 00:11:32.177]  Making secure communication tools easier to use.
[00:11:32.377 --> 00:11:35.920]  I personally have no idea how to keep myself secure online.
[00:11:36.120 --> 00:11:36.600]  I'm learning.
[00:11:37.160 --> 00:11:39.582]  But they also want to reform Executive Order 12333.
[00:11:39.842 --> 00:11:50.550]  No one really ever talks about that, but this is the primary authority that the NSA uses to engage in the surveillance of people outside of the United States.
[00:11:50.990 --> 00:11:56.773]  So the Electronic Frontier Foundation has already started working on that first phase of reform.
[00:11:57.214 --> 00:11:59.675]  There are several other steps that you can take as well.
[00:11:59.835 --> 00:12:03.938]  Please click on the link that will be provided at the YouTube video.
[00:12:04.278 --> 00:12:06.519]  But this is all a call to action.
[00:12:06.579 --> 00:12:07.820]  We've got to be a part of this.
[00:12:07.880 --> 00:12:13.363]  We can't be sheep and lemmings and just let all of this get out of hand.
[00:12:13.463 --> 00:12:14.444]  Surveillance is here.
[00:12:14.464 --> 00:12:15.924]  AI is coming.
[00:12:16.405 --> 00:12:18.006]  And you know, it's not all bad.
[00:12:18.786 --> 00:12:19.788]  Human ingenuity.
[00:12:20.269 --> 00:12:21.391]  We created this.
[00:12:21.451 --> 00:12:23.995]  It's not that those guys are any better than the rest of us.
[00:12:24.156 --> 00:12:26.700]  Heck, half of them are kids.
[00:12:26.760 --> 00:12:30.046]  I mean, they're just kids at this technology conference.
[00:12:32.105 --> 00:12:35.386]  It's almost a blessing to see what humans are capable of doing.
[00:12:35.726 --> 00:12:36.366]  Check this out.
[00:12:36.706 --> 00:12:41.967]  They basically built the Star Trek teleporter with a 3D printer.
[00:12:42.288 --> 00:12:51.570]  Now this is a device, it's dubbed Scotty, and it digitizes an object in one place, destroys it in the process, and then it rebuilds it in a whole
[00:12:52.210 --> 00:12:52.510]  I think so.
[00:13:16.417 --> 00:13:18.378]  One type of material, which is plastic.
[00:13:18.798 --> 00:13:22.799]  So we're a long way off from beaming ourselves to other planets.
[00:13:22.939 --> 00:13:24.060]  But what?
[00:13:24.700 --> 00:13:25.840]  Humans did that.
[00:13:26.120 --> 00:13:31.582]  That is how amazing, that is how amazing the capability of human ingenuity is.
[00:13:31.602 --> 00:13:35.203]  That's why we can't stop ourselves from learning about this technology.
[00:13:35.243 --> 00:13:36.204]  We shouldn't fear it.
[00:13:36.624 --> 00:13:42.466]  But we just need to make sure that is for the benefit of humanity.
[00:13:42.486 --> 00:13:43.446]  AI has a future.
[00:13:43.646 --> 00:13:45.267]  The question is, do we?
[00:13:46.367 --> 00:13:59.273]  So speaking about dispelling the myth of this AI explosion and robots are going to, you know, destroy humanity and that's kind of a way that media and science fiction can sell, you know, sell their product.
[00:13:59.793 --> 00:14:13.100]  But we do have people like Stephen Hawking or Elon Musk saying that, you know, there is a reason for concern and Elon Musk donates a lot of money to this research where they're going to put forth this effort to make sure AI doesn't get ahead of us.
[00:14:13.781 --> 00:14:16.674]  Is there a reason to be concerned and what can we do about it?
[00:14:18.075 --> 00:14:33.746]  So, there is a reason to be concerned in the long term, because the direction that AI has been going, and not just AI, control theory, operations research, there are other disciplines aimed at exactly the same thing, which is producing the capability for making high-quality decisions.
[00:14:34.046 --> 00:14:34.726]  That's all it means.
[00:14:36.928 --> 00:14:47.755]  And if you have a system that can make very high-quality decisions, which means it takes into account much more information than a human could do, it's able to look further in the future than a human could do,
[00:14:50.297 --> 00:14:54.961]  The third part of the triangle, so to speak, is what's the objective?
[00:14:55.702 --> 00:14:58.805]  So it's using lots of information, it's looking far ahead into the future, that's great.
[00:14:59.486 --> 00:15:01.808]  What's the objective that it's trying to achieve?
[00:15:03.169 --> 00:15:12.017]  If that objective is not perfectly aligned with the values of us humans, then that creates the possibility for
[00:15:13.171 --> 00:15:14.672]  Bad things to happen.
[00:15:15.853 --> 00:15:18.475]  That, in some sense, is the definition of conflict.
[00:15:20.476 --> 00:15:27.641]  And getting into a conflict with systems that are more capable than we are doesn't sound like a good idea.
[00:15:28.301 --> 00:15:36.707]  So the solution seems to be that we have to make sure the values of the machine are aligned with the values of the human race.
[00:15:38.874 --> 00:15:44.578]  So, one way to get that to happen is for the machine to observe what humans do.
[00:15:45.699 --> 00:15:50.683]  Not only what we do, but what is our attitude to what we do and what other people do.
[00:15:51.243 --> 00:15:57.407]  So, if someone gets put in jail, we learn that that was an act contrary to human values.
[00:15:57.968 --> 00:16:05.734]  If someone gets up in the morning, makes a cup of coffee, then the machine learns that having some coffee in the morning
[00:16:07.172 --> 00:16:18.603]  Who gets to decide what is positively beneficial?
[00:16:19.024 --> 00:16:23.207]  Is it going to be some government agency or some bureaucracy?
[00:16:23.288 --> 00:16:24.128]  Who gets to decide?
[00:16:24.168 --> 00:16:27.632]  Because, for instance, if you take autonomous drones,
[00:16:28.618 --> 00:16:36.283]  Well, what the human would want them to do is be really accurate and have precision, you know, so that it'll strike its target.
[00:16:36.843 --> 00:16:43.507]  But maybe the person on the receiving end of that drone strike, that's not going to be beneficial to them.
[00:16:44.388 --> 00:16:54.554]  And we know sometimes war is waged for the wrong reasons, and people decide for the wrong reasons that they want this machine to do their bidding, basically.
[00:16:56.867 --> 00:16:59.509]  I mean, that's not really something that people can even backtrack.
[00:16:59.569 --> 00:17:09.755]  That technology is already there, but so who kind of gets to decide what's beneficial and is there any way to control some of the systems that are already growing?
[00:17:11.116 --> 00:17:12.037]  So that's a great question.
[00:17:12.057 --> 00:17:19.761]  I think the issue of autonomous weapons is a very immediate one, in some ways much more immediate than the kinds of things we've just been talking about.
[00:17:21.681 --> 00:17:34.210]  And my own view is that it's a mistake to think just about replacing current functions that are done by humans with machines.
[00:17:34.250 --> 00:17:42.556]  So right now we have drones, but the targeting decisions are made by a human who is getting the remote video feed from the drone.
[00:17:43.196 --> 00:17:47.179]  And the human identifies the target and the human pulls the trigger.
[00:17:48.766 --> 00:17:54.928]  And so people are talking about, is it acceptable to replace that particular function with a computer program?
[00:17:57.248 --> 00:18:11.412]  And the argument then focuses on accuracy and moral agency and liability and responsibility and whether it exactly fits the Geneva Convention and issues like that.
[00:18:13.484 --> 00:18:22.532]  And that argument is playing out right now in the United Nations, so it will get resolved one way or the other, and that's the right place.
[00:18:22.973 --> 00:18:33.262]  I think the collection of nations of the world need to decide on what kinds of military capabilities are actually allowable.
[00:18:36.215 --> 00:18:39.819]  The reason I think it's a mistake is because it assumes that everything remains the same.
[00:18:40.319 --> 00:18:46.265]  That we just replace an existing human function with an algorithm or a machine and nothing else changes.
[00:18:46.285 --> 00:18:59.197]  But in fact, if you have autonomous weapons, you're going to have an arms race of autonomous weapons, because once you have autonomous attack weapons, then you need autonomous defense weapons, because human reaction times are going to be too slow.
[00:19:01.059 --> 00:19:05.502]  You're going to then look at autonomous attack weapons that are anti-personnel.
[00:19:07.363 --> 00:19:13.247]  For example, clouds of miniaturized flying robots against which it's impossible to defend.
[00:19:13.608 --> 00:19:27.377]  And you can imagine getting to a situation where the life expectancy of a human soldier would be 10 seconds on the battlefield, and the life expectancy of a civilian, if a government used those weapons against its own population, would be 2 seconds.
[00:19:29.682 --> 00:19:35.825]  And you could wipe out every inhabitant of a city in a few minutes for a few million dollars.
[00:19:36.805 --> 00:19:39.907]  This is just not a direction that I think we should go.
[00:19:41.487 --> 00:19:49.891]  We've made decisions about biological weapons, for example, in the past, that this is not a direction we should go, and we stopped.
[00:19:51.632 --> 00:19:57.375]  And my view is that the arms race that would ensue if we do go ahead with autonomous weapons would be disastrous.
[00:19:58.639 --> 00:20:00.302]  The knowledge of the ancients.
[00:20:00.602 --> 00:20:04.167]  Tried and true, trusted herbs and extracts.
[00:20:04.427 --> 00:20:07.030]  Fused with the latest nutraceutical science.
[00:20:07.371 --> 00:20:10.775]  Introducing the all-new Ancient Defense Herbal Immunity Blend.
[00:20:10.996 --> 00:20:15.702]  Crafted with over 14 key ancient herbs and extracts to supercharge
[00:20:15.742 --> 00:20:16.362]  We're good to go!
[00:20:44.079 --> 00:20:46.984]  With exciting new advances in nutraceutical science.
[00:20:47.284 --> 00:20:50.750]  For a limited time, get 25% off on this introductory offer.
[00:20:50.870 --> 00:20:53.434]  Visit ancientdefense.com or call 888-253-3139.
[00:20:53.454 --> 00:20:53.975]  AncientDefense.com
[00:20:58.559 --> 00:21:01.142]  Every year we make resolutions to lose weight and get in shape.
[00:21:01.242 --> 00:21:02.403]  And the truth is, it's hard.
[00:21:02.663 --> 00:21:04.125]  Even with diet and exercise.
[00:21:04.325 --> 00:21:09.370]  Because of toxic food in our environment that is stressing our bodies more than ever before.
[00:21:09.511 --> 00:21:16.358]  Working with experts in nutrition and biochemistry, I found that super high quality nutraceuticals, in addition to my diet and exercise,
[00:21:16.658 --> 00:21:18.621]  Worthy answers that synergistically worked.
[00:21:18.881 --> 00:21:25.411]  I can see the drastic changes every day with the amount of weight I've lost, my increased stamina, and more of a twinkle in my eye.
[00:21:25.731 --> 00:21:31.640]  That's why we are now so excited to launch the InfoWars Life Resolution Pack, combining three essential formulations.
[00:21:32.120 --> 00:21:39.846]  Oxygen-Based Cleanser Oxy Powder, The Secret 12 Bioavailable Vitamin B12, and your choice of Super Female or Super Male Vitality.
[00:21:40.026 --> 00:21:46.611]  Now all available at a discounted price to you and your family to bring in the new year and make 2015 a true success.
[00:21:46.991 --> 00:21:48.252]  That's Infowarslife.com or 888-253-3139.
[00:21:48.272 --> 00:21:51.294]  2015 is the year to do it and it all starts at Infowarslife.com.
[00:22:21.032 --> 00:22:25.395]  Well, we know that the CIA has been controlling corporate media for decades.
[00:22:25.715 --> 00:22:30.559]  That came out in the 70s when those revelations came out during the Church Committee.
[00:22:30.919 --> 00:22:46.310]  But now, Dr. Udlo Ulfkot, he's the editor of a Frankfurt paper, he says that the CIA routinely plants stories in the establishment media, and this includes stories that are not only untrue, but they've resulted in the death of thousands of people.
[00:22:46.730 --> 00:22:59.193]  And he points out some examples of stories that he was ordered to plant in his newspaper over the years, including a story that Libyan President Muammar Gaddafi was building poison gas factories in 2011.
[00:22:59.673 --> 00:23:05.015]  There was a bogus chemical weapons stories that were appearing in the media prior to the invasion of Libya.
[00:23:05.255 --> 00:23:07.515]  Of course, that ultimately resulted in the death of 30,000 people.
[00:23:10.396 --> 00:23:15.479]  Similar fake stories were also used as war propaganda in the lead up to the invasion of Iraq.
[00:23:16.119 --> 00:23:19.681]  These were summarily dismissed as intelligence failures.
[00:23:20.161 --> 00:23:22.482]  Never forget Nurse Naira.
[00:23:23.302 --> 00:23:25.003]  But look at this double standard.
[00:23:25.464 --> 00:23:33.948]  On Monday, a former CIA employee, Jeffrey Sterling, was convicted of giving classified information to a New York Times reporter.
[00:23:34.488 --> 00:23:41.072]  The leak concerned an effort by the CIA to sabotage plans for an Iranian nuclear reactor.
[00:23:41.772 --> 00:23:46.355]  Now, the Attorney General Eric Holder said that the disclosures place lives at risk.
[00:23:46.495 --> 00:23:47.475]  And get this!
[00:23:48.115 --> 00:23:56.320]  He said that they constituted an egregious breach of the public trust by someone who had sworn to uphold it.
[00:23:56.340 --> 00:23:57.361]  Oh, the irony!
[00:23:57.441 --> 00:23:58.701]  It's maddening there.
[00:23:58.981 --> 00:24:01.303]  They say the very things that they are guilty of.
[00:24:01.923 --> 00:24:13.472]  But of course, no such criticism was directed at the CIA, which has controlled the corporate media for decades, constantly filling them with the information that they want them to report.
[00:24:13.852 --> 00:24:18.616]  And now it's not just the federal government, but it's trickling down to the state level.
[00:24:20.100 --> 00:24:26.185]  I've been to several press conferences and oftentimes they will tell you what they want you to hear, not so much what you want to know.
[00:24:26.546 --> 00:24:34.893]  This could be as simple as just handing you a press release, these are the only topics that we want to talk about, or a politician abruptly leaving the stage after their speech has concluded.
[00:24:35.273 --> 00:24:39.797]  So I'm very curious why a governor in Indiana feels the need for his own media outlet.
[00:24:40.217 --> 00:24:49.841]  It could be very benign subject matter, such as maybe talking about the Hoosiers, you know, pictures of his family and friends, hanging out with the constituents at barbecues and so forth.
[00:24:50.221 --> 00:24:55.003]  But is it unethical for somebody to use taxpayer funds to promote themselves in a positive light?
[00:24:55.364 --> 00:25:02.867]  Governor Mike Pence is starting a state-run taxpayer-funded news outlet that will make pre-written news stories available to Indiana media.
[00:25:03.507 --> 00:25:09.169]  As well as sometimes break news about his administration, according to documents obtained by the Indianapolis Star.
[00:25:09.509 --> 00:25:18.572]  The new service has two dedicated employees, whose combined salary is nearly $100,000, according to a search of the state employees' salary data.
[00:25:19.152 --> 00:25:22.773]  Another journalist put it this way, Mike Pence's horrible idea.
[00:25:23.757 --> 00:25:28.018]  In recent months, the administration has hired staff, including a former journalist.
[00:25:28.359 --> 00:25:31.740]  They have written test stories and quietly work toward the launch date.
[00:25:32.040 --> 00:25:34.040]  And this is just in news media.
[00:25:34.080 --> 00:25:37.041]  This is the organization that wants to launch the news outlet.
[00:25:37.081 --> 00:25:39.782]  And I do believe it's going to start up pretty soon.
[00:25:40.102 --> 00:25:43.344]  And for all the previously mentioned reasons, yes, this does concern me.
[00:25:43.624 --> 00:25:45.004]  But it's not just in Indiana.
[00:25:45.344 --> 00:25:50.246]  We see via the FCC the government is controlling a lot of what you see on mainstream television.
[00:25:50.846 --> 00:26:04.336]  In 2014, the FCC Commissioner lifted a lid on a shocking White House proposal that would put researchers in the newsroom with reporters, editors, and station owners to find out how they decided which stories to run with.
[00:26:04.636 --> 00:26:11.882]  It's very shocking indeed, and yes, I do believe that will lead to media censorship, people being intimidated by constantly having somebody looking over their shoulder.
[00:26:12.302 --> 00:26:17.566]  Looking to the broader military community, all leaders must understand the role of the press and the importance of working with the media.
[00:26:42.912 --> 00:26:44.733]  And we cannot hide our bad news stories.
[00:26:45.934 --> 00:26:51.478]  Bad news gets out one way or the other, and we must come to terms with telling the bad stories as well as the good.
[00:26:52.519 --> 00:26:58.123]  When bad things happen, the American people should hear it from us, not as a scoop on the Drudge Report.
[00:27:00.005 --> 00:27:03.968]  Unlike many fine red wines, bad news does not get better with age.
[00:27:11.744 --> 00:27:22.892]  Sold out for weeks due to the difficult and extensive proprietary process behind its creation, the exclusive InfoWars Life Secret 12 formulation is now back in stock in the last limited shipment of 2014.
[00:27:23.112 --> 00:27:36.902]  The most bioactive form that has been created with our proprietary process, this ultra-clean vitamin B12 nutraceutical has been carefully crafted and developed over the last two years and is based on cellular science of how your body actively absorbs essential nutrients.
[00:27:37.342 --> 00:27:40.163]  Secret 12 is taken by mouth, right on the tongue, and then swallowed.
[00:27:40.443 --> 00:27:41.623]  No needles, no injections.
[00:27:41.863 --> 00:27:45.884]  Vitamin B12 deficiency is linked to scores of serious problems.
[00:27:46.184 --> 00:27:55.347]  And Secret 12 is a fusion of two organic proprietary forms of Vitamin B12, bringing you a true nutraceutical quality Vitamin B12.
[00:27:55.807 --> 00:27:56.167]  Secret 12.
[00:27:56.887 --> 00:27:58.768]  Secret 12 is an excellent Christmas gift.
[00:27:59.068 --> 00:27:59.509]  I think so.
[00:28:19.451 --> 00:28:23.253]  There's a reason over 88% of New Year's resolutions fail.
[00:28:23.393 --> 00:28:29.496]  Make this year different by equipping yourself with Oxy Powder, the next level in cleansing the body naturally.
[00:28:29.856 --> 00:28:35.659]  Using Super Oxygenation Oxy Powder, available through Infowarslife.com, gently cleanses the body.
[00:28:35.839 --> 00:28:37.760]  While you sleep with easy capsules.
[00:28:38.080 --> 00:28:43.763]  Tens of thousands of individuals have used Oxy-Powder to cleanse their bodies and aid in their transformations.
[00:28:44.183 --> 00:28:49.486]  Even InfoWars Nightly News Director Rob Dew has been using Oxy-Powder with incredible success.
[00:28:49.806 --> 00:28:52.147]  Took it that first day, then I took it for six more days after that.
[00:28:52.307 --> 00:28:53.448]  Twelve pounds melted off.
[00:28:53.608 --> 00:28:54.789]  In about a week, I'd say a week.
[00:28:54.949 --> 00:28:55.389]  Seven days.
[00:28:55.949 --> 00:28:57.571]  2015 can be different.
[00:28:57.692 --> 00:29:00.635]  Diet and exercise are important, but a lot of us have already tried that.
[00:29:00.915 --> 00:29:02.718]  Oxy-Powder flushes it out.
[00:29:03.118 --> 00:29:05.821]  Secure your Oxy-Powder at Infowarslife.com.
[00:29:06.102 --> 00:29:07.964]  That's Infowarslife.com or 888-253-3139.
[00:29:23.131 --> 00:29:27.893]  Were you one of those poor souls who got stuck in the snowmageddon?
[00:29:28.233 --> 00:29:32.854]  Dan Bodondi reported that they even declared martial law in Rhode Island.
[00:29:32.894 --> 00:29:35.215]  We're going to get a report coming from him later.
[00:29:35.615 --> 00:29:38.036]  But it was the snowpocalypse that never
[00:29:38.496 --> 00:29:39.076]  Was.
[00:29:39.236 --> 00:29:40.136]  It never happened.
[00:29:40.236 --> 00:29:42.897]  Forecasters failed on the blizzard.
[00:29:43.257 --> 00:29:50.319]  Meteorologists were forced to apologize for exaggerating this snowmageddon, their snowmageddon predictions.
[00:29:50.719 --> 00:29:59.361]  Now, of course, this over-exaggeration was predicted to be the worst ever blizzard to ever hit the East Coast just two days ago.
[00:29:59.641 --> 00:30:06.243]  So, in two days, they can't even have accuracy of what is supposed to be the worst blizzard ever.
[00:30:06.983 --> 00:30:09.025]  Now, it was a complete dud.
[00:30:09.345 --> 00:30:23.075]  However, we are expected to believe 100-year-old climate models that purport to show that the Earth is going to be decimated by global warming, when they can't even predict snowpocalypse two days earlier.
[00:30:24.436 --> 00:30:30.801]  We are facing most likely one of the largest snowstorms in the history of this city.
[00:30:30.941 --> 00:30:32.842]  As much as two feet of snow
[00:30:33.871 --> 00:30:37.572]  Potentially pushing on closer to three feet of snow.
[00:30:37.592 --> 00:30:44.035]  Well, it looks like the epic snowstorm of the Northeast has turned into an epic fail for weather predictions.
[00:30:44.455 --> 00:30:49.157]  Yesterday, we had more than 7,700 flights in and out of the Northeast canceled.
[00:30:49.637 --> 00:30:51.880]  Most of those aren't going to get started again until Wednesday.
[00:30:51.900 --> 00:30:54.502]  We had schools, businesses, government offices closed.
[00:30:54.803 --> 00:30:56.925]  Shoppers emptied the store shelves.
[00:30:57.105 --> 00:30:59.067]  Bridges, tunnels were closed.
[00:30:59.147 --> 00:31:00.389]  The subway was closed.
[00:31:00.629 --> 00:31:02.351]  And then, of course, the traffic ban.
[00:31:02.611 --> 00:31:06.736]  de Blasio said, get off the roads, get off the streets, get off the sidewalks.
[00:31:07.156 --> 00:31:14.661]  And he threatened that people would be subject to summonses, in other words, tickets, or arrest if they were out on the street past 11 p.m., a curfew.
[00:31:14.841 --> 00:31:22.706]  So much for the NYPD's new policy of not issuing tickets or arresting people unless absolutely necessary.
[00:31:22.967 --> 00:31:29.611]  de Blasio said that even bicycle delivery men would be barred from the roads until everything is safe.
[00:31:29.971 --> 00:31:30.632]  So there you have it.
[00:31:31.092 --> 00:31:35.455]  The Northeast shut down due to a failed climate prediction.
[00:31:36.015 --> 00:31:36.696]  Hold that thought.
[00:31:37.496 --> 00:31:42.881]  It was just a year ago that we went to the American Meteorological Society's meeting here in Austin.
[00:31:43.661 --> 00:31:46.804]  There we saw scientists who were actually doing science.
[00:31:46.844 --> 00:31:53.349]  They would create models that would try to predict the weather, then they would measure that against the realities and try to adjust their models.
[00:31:53.789 --> 00:31:55.510]  That's the way real science is done.
[00:31:56.411 --> 00:32:02.480]  Climate change, however, uses models that extend over decades or centuries.
[00:32:02.540 --> 00:32:09.590]  There's very little experiential feedback into that model that allows you to know if you've got something that's real or not.
[00:32:09.931 --> 00:32:11.273]  But of course, we've been able to see
[00:32:11.773 --> 00:32:15.657]  Some aspects that indicate that these models have massively failed.
[00:32:15.957 --> 00:32:19.981]  We've seen CO2 rise very rapidly without an increase in temperature.
[00:32:20.242 --> 00:32:22.684]  We've seen the humidity not go up as predicted.
[00:32:22.724 --> 00:32:27.629]  And that's a key part of any kind of global warming prediction, global warming modeling.
[00:32:27.729 --> 00:32:33.475]  And of course, nowhere in any of their models is there a 20-year pause in global warming.
[00:32:33.775 --> 00:32:35.036]  Yet we have seen that.
[00:32:35.817 --> 00:32:40.661]  We're supposed to rely on these predictions because they're coming from people of authority.
[00:32:41.121 --> 00:32:46.946]  We're not supposed to be skeptical about the weather reports 100 years from now.
[00:32:46.966 --> 00:32:48.768]  Weather models don't work.
[00:32:49.168 --> 00:32:59.437]  We should not shut down the entire globe based on a model that cannot be verified and what we have seen of it in the short term indicates that it is not working.
[00:33:00.117 --> 00:33:10.447]  Global warming, climate change as they're now trying to call it, is nothing but a massive transfer of power and wealth to a few elites and to the government.
[00:33:11.148 --> 00:33:13.130]  For InfoWars Nightly News, I'm David Knight.
[00:33:14.192 --> 00:33:15.492]  That's it for the show tonight.
[00:33:15.572 --> 00:33:18.753]  If you're watching us on YouTube, hit the subscribe button.
[00:33:18.773 --> 00:33:24.734]  Become a subscriber to the Alex Jones YouTube channel, and then head over to PrisonPlanet.tv.
[00:33:25.115 --> 00:33:35.437]  There, if you become a subscriber, you will get instant access to over 18 years worth of content that you will not find on YouTube, and you can share your username and password
[00:33:35.757 --> 00:33:38.242]  With up to 20 people at the same time.
[00:33:38.582 --> 00:33:41.307]  And of course, you're helping us out here at InfoWars.
[00:33:41.728 --> 00:33:43.952]  Thanks for tuning in tonight, and we'll see you here tomorrow, 7 p.m.
[00:33:44.032 --> 00:33:44.313]  Central.
[00:33:50.586 --> 00:33:54.388]  City of Austin tap water versus filtered City of Austin tap water.
[00:33:54.808 --> 00:33:56.008]  I didn't, I taste dirt in it.
[00:33:56.068 --> 00:33:57.189]  God knows what's in this.
[00:33:57.329 --> 00:33:58.309]  This has an aftertaste.
[00:33:58.349 --> 00:33:59.930]  Tastes like Austin water?
[00:34:00.190 --> 00:34:01.050]  Yeah, it does.
[00:34:01.110 --> 00:34:05.272]  These people just sampled City of Austin tap water straight from the faucet.
[00:34:05.512 --> 00:34:11.635]  Next, we had them try a sample of tap water filtered through the ProPure G2.0 filtration system.
[00:34:11.835 --> 00:34:12.575]  I call it H2O.
[00:34:12.595 --> 00:34:14.136]  That one is better.
[00:34:14.216 --> 00:34:15.196]  Tastes like nothing.
[00:34:15.476 --> 00:34:16.877]  Yep, I know what good water tastes like.
[00:34:16.937 --> 00:34:17.437]  It's good water.
[00:34:17.537 --> 00:34:26.085]  Most tap water contains added substances, like fluoride, chlorine, Monsanto's deadly pesticide, glyphosate, and many others.
[00:34:26.506 --> 00:34:33.993]  Studies prove that these substances are linked to an assortment of major health issues, including tooth decay, lowered IQ, and even cancer.
[00:34:34.273 --> 00:34:36.796]  It tastes like you're drinking out of the lake when you're drinking tap water.
[00:34:37.396 --> 00:34:39.699]  It has that processed flavor to it.
[00:34:40.039 --> 00:34:49.629]  The ProPureÂ® G2.0 filtration system removes these deadly substances and many more, leaving only fresh-tasting, deliciously clean water.
[00:34:49.649 --> 00:34:51.371]  Okay, this is very tasty.
[00:34:51.471 --> 00:34:52.132]  It's good water.
[00:34:52.828 --> 00:34:53.248]  Refreshing?
[00:34:53.688 --> 00:34:54.049]  It's good!
[00:34:54.569 --> 00:34:56.910]  Go to InfoWarsStore.com today.
[00:34:57.310 --> 00:35:01.152]  Use promo code WATER and save 10% off your ProPure purchase.
[00:35:01.652 --> 00:35:08.115]  Again, that's InfoWarsStore.com or call 1-888-253-3139.
[00:35:10.256 --> 00:35:14.197]  You are watching the InfoWars Nightly News, which airs 7 p.m.
[00:35:14.237 --> 00:35:16.698]  Central at InfoWarsNews.com.
[00:35:16.818 --> 00:35:20.320]  And your support is helping us defend liberty worldwide.
